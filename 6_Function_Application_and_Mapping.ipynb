{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9pQBcS4QQQC"
   },
   "source": [
    "# Function Application and Mapping\n",
    "\n",
    "---\n",
    "What we  will learn in this chapter might be some of the most important concepts and skills that we will cover in this entire course. We will be tying much of what we have learned in previous chapters together, and the practicality will become clear as you read and work through the exercises.\n",
    "\n",
    "Function application and mapping simply refers to proccessing the entries of a `DataFrame` to better suite your needs.\n",
    "\n",
    "For instance, suppose a data set your are analyzing contains a column describing the delay for a commercial flight and we are interested in seeing the distribution of delay times across weekdays. We could group all the flights that occurred on the same weekday over a time period and compare the aggregated delay times for each day to the total delay time over the week. If the delays were evenly distributed then the result might look like:\n",
    "\n",
    "| Sunday | Monday | Tuesday | Wednesday | Thursday | Friday | Saturday |\n",
    "|:----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "| 0.1428| 0.1428 |0.1428|0.1428|0.1428|0.1428|0.1428|\n",
    "\n",
    "But if one day in particular consistently had more delays then it might look something like this:\n",
    "\n",
    "| Sunday | Monday | Tuesday | Wednesday | Thursday | Friday | Saturday |\n",
    "|:----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "| 0.1| 0.4 |0.1|0.1|0.1|0.1|0.1|\n",
    "\n",
    "We will learn how to do this type of analysis and more in the chapter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZwsIw7ZQnr-"
   },
   "source": [
    "# Preparing Our Environment\n",
    "\n",
    "---\n",
    "\n",
    "`pandas` has implemented useful and intuitive functionality for function application and mapping and will be the only resource we need in this chapter. Please run the code in the cell below to import `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCz5hW3A4OoZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OqcadNZH4qBy"
   },
   "source": [
    "# About the Data\n",
    "\n",
    "---\n",
    "\n",
    "We will be using the same subset from the publicly available dataset from the Center for Medicare & Medicaid Services website ([`CMS` website](https://www.cms.gov/OpenPayments/Explore-the-Data/Dataset-Downloads.html)), and as a reminder our subset of data contains the following columns:\n",
    "\n",
    "| Column |Description|\n",
    "|:----------|-----------|\n",
    "| `unique_id`| A unique identifier for a Medicare claim to CMS |\n",
    "| `doctor_id` | The Unique Identifier of the doctor who <br/> prescribed the medicine  |\n",
    "| `specialty` | The specialty of the doctor prescribed the medicine |\n",
    "| `medication` | The medication prescribed |\n",
    "| `nb_beneficiaries` | The number of beneficiaries the <br/> medicine was prescribed to  |\n",
    "| `spending` | The total cost of the medicine prescribed <br/>for the CMS |\n",
    "\n",
    "The file that we will be using throughout this chapter is named 'spending_10k.csv' and, relative to our current working directory, this file is in the folder 'Data'. We will be reading this .`csv` file and saving its contents into the `DataFrame` named `spending_df`. We also know ahead of time that this file contains the column `unique_id` which we will want to use to index our `DataFrame`. Furthermore, the `doctor_id` column should be interpretted as an object type column. Please run the code in the cell below to have access to this data set so you can follow along with the examples presented in this chapter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pcmiQ3Ro-rdO"
   },
   "outputs": [],
   "source": [
    "spending_df = pd.read_csv('Data/spending_10k.csv', index_col='unique_id', dtype={'doctor_id': 'object'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mvT9LnMRA7fW"
   },
   "source": [
    "# Exercise 6.0: Importing the Honolulu Flights Data Set\n",
    "\n",
    "For some of the exercises in this chapter we will again be working with a data set containing information about all the arriving and departing flights in and out of the Honolulu aiport, HNL, on the Island of Oahu in December 2015. This data set was introduced in chapter 3: `DataFrame` Attributes and Arithmetic\n",
    "\n",
    "Please run the following code cell which will parse the 'honolulu_flights.csv' file, and build the `HNL_flights_df DataFrame` before trying the exercises in this chapter related to the Honolulu flights data set.\n",
    "\n",
    "Pleases recall that this data set contains the following columns:\n",
    "\n",
    "| Column |Description|\n",
    "|:----------|-----------|\n",
    "| `YEAR` | The year of the flight  |\n",
    "| `MONTH` |  The month of the flight |\n",
    "| `DAY` |  The day of the flight |\n",
    "| `DAY_OF_WEEK` |  The day of the week of the flight |\n",
    "| `FLIGHT_NUMBER` |  The flight number of the flight |\n",
    "| `ORIGIN_AIRPORT` |  The origin airport of the flight  |\n",
    "| `DESTINATION_AIRPORT` |  The destination airport of the flight |\n",
    "| `DEPARTURE_DELAY` |  The departure delay of the flight  |\n",
    "| `DISTANCE` |  The distance of the flight in miles |\n",
    "| `AIR_TIME` |  The flight time without taxiing in minutes |\n",
    "| `ARRIVAL_DELAY` |  The arrival delay of the flight  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2UHXk8RoBT4F"
   },
   "outputs": [],
   "source": [
    "HNL_flights_df = pd.read_csv('Data/honolulu_flights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Processing Vs. Group Specific Processing\n",
    "\n",
    "Function application falls into one of two categories:\n",
    "\n",
    "1. **Global Processing**\n",
    "2. **Group Specific Processing**\n",
    "\n",
    "Global processing is applying the same function to every entry (referring to a singular data point or an entire row or column) in a `Series` or `DataFrame`. Group specific processing, on the other hand, is applying functions to entries that belong to a certain group based on some defining characteristic. \n",
    "\n",
    "We will begin by covering global processing in the following cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sHGSMIrMeeGK"
   },
   "source": [
    "## Global Processing\n",
    "\n",
    "In one clever way or another, every global processing problem you will ever run into when working with `DataFrames` will fit into one of two levels of granularity. Corresponding to these two levels are two `DataFrame` methods, `apply()` and `applymap()`.\n",
    "\n",
    "To apply a function to every row or column of a `DataFrame` we use the `apply()` `DataFrame` method. The `apply()` method takes a function that will be applied to the specified axis (columns or rows), the axis, and other keyword arguments that are defined by default. Depending on the function passed to the `apply()` can behave in the same way as the `applymap()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sHGSMIrMeeGK"
   },
   "source": [
    "### Global Processing-apply()\n",
    "Let us look at two examples use cases, using a reducing function, and a universal function. The function passed to the `apply()` method will process a `Series`, either a `DataFrame` row or column depending on the axis parameter, and return a result. \n",
    "\n",
    "Most of the time when you call the `apply()` method you should be using a reducing function. A reducing function is one which takes a `Series` object and reduces the `Series` to a either a new `Series` or a single entry using a process that relies on data in the `Series`. You are already familiar with some reducing functions such as the `Series` `sum()` method, which returns the sum of all the entries in the calling `Series`. Consider the following example of calling `apply()` with a reducing function.\n",
    "\n",
    "```python\n",
    ">>> df = pd.DataFrame([[ 0,  3,  6], [ 9, 12, 15], [18, 21, 24]], columns=['a', 'b', 'c'])\n",
    ">>> def square_sum(x_series):\n",
    ">>>    return x_series.sum() ** 2\n",
    ">>> df.apply(square_sum, axis=1) # apply to each row\n",
    "0      81\n",
    "1    1296\n",
    "2    3969\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "The reducing function, `square_sum()` in the example above sums all the entries in the `Series` and the squares the result. You can define custom reducing functions just like we showed above to to achieve your desired analysis.\n",
    "\n",
    "A universal function will return a new `Series` that was created by universally applying the same procedure to each `Series` entry. A universal function can be defined using the `Series` `map()` method. The `map()` method will take a function as an argument which will process each individual `Series` entry according to the function definition. For instance refer to the following code example.\n",
    "\n",
    "```python\n",
    ">>> df = pd.DataFrame([[ 0,  3,  6], [ 9, 12, 15], [18, 21, 24]], columns=['a', 'b', 'c'])\n",
    ">>> def divide_by_three(x_series):\n",
    ">>>    return x_series.map(lambda x: x / 3)\n",
    ">>> df.apply(divide_by_three, axis=0) # apply to each column\n",
    "     a    b    c\n",
    "0  0.0  1.0  2.0\n",
    "1  3.0  4.0  5.0\n",
    "2  6.0  7.0  8.0\n",
    "```\n",
    "\n",
    "The example above shows how the `apply()` method behaves when a universal function is passed as the argument. The resulting `DataFrame` is constructed from original `DataFrame` except each individual entry is divided by three. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      81\n",
       "1    1296\n",
       "2    3969\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[ 0,  3,  6], [ 9, 12, 15], [18, 21, 24]], columns=['a', 'b', 'c'])\n",
    "def square_sum(x_series):\n",
    "    return x_series.sum() ** 2\n",
    "df.apply(square_sum, axis=1) # apply to each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c\n",
       "0  0.0  1.0  2.0\n",
       "1  3.0  4.0  5.0\n",
       "2  6.0  7.0  8.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[ 0,  3,  6], [ 9, 12, 15], [18, 21, 24]], columns=['a', 'b', 'c'])\n",
    "def divide_by_three(x_series):\n",
    "    return x_series.map(lambda x: x / 3)\n",
    "df.apply(divide_by_three, axis=0) # apply to each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sHGSMIrMeeGK"
   },
   "source": [
    "### Global Processing-applymap()\n",
    "There is a shorthand way achieve the same exact behavior shown in the example of applying a universal function in the **Global Processing-apply()** cell above, and the method is appropriately named `applymap()`, as first we call the `apply()` `DataFrame` method and then we call the `map()` method. \n",
    "\n",
    "To apply a function to every individual element in a `DataFrame` we can use the `applymap()` `DataFrame` method.  The `applymap()` method is a function which takes one positional argument as input and that is a callable function which takes a single value and returns a single value. The `applymap()` method will apply the function passed to every single entry in the calling `DataFrame` and return a new `DataFrame` with the processed entries.\n",
    "\n",
    "Let us see a simple example. We will construct a `DataFrame` `df` that is $3 \\times 3$, i.e. there are three rows and three columns. The entries will be consecutive multiples of 3. To each entry we will apply the anonymous function: `lambda x: x / 3` which will divide a given input by 3. The result will be a new $3 \\times 3$ `DataFrame` with the same index and columns as the caller with entries that are the results of the passed function.\n",
    "\n",
    "```python\n",
    ">>> df = pd.DataFrame([[ 0,  3,  6], [ 9, 12, 15], [18, 21, 24]], columns=['a', 'b', 'c'])\n",
    ">>> df.applymap(lambda x: x / 3)\n",
    "     a    b    c\n",
    "0  0.0  1.0  2.0\n",
    "1  3.0  4.0  5.0\n",
    "2  6.0  7.0  8.0\n",
    "```\n",
    "\n",
    "This type of processing is relatively rare since it should be the case that it makes sense to apply the same function to every entry regardless of its location. For example, in the `spending_df` `DataFrame` there are few functions that would be reasonable to apply globally. But when you need this functionality, the `applymap()` function is quite useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c\n",
       "0  0.0  1.0  2.0\n",
       "1  3.0  4.0  5.0\n",
       "2  6.0  7.0  8.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[ 0,  3,  6], [ 9, 12, 15], [18, 21, 24]], columns=['a', 'b', 'c'])\n",
    "df.applymap(lambda x: x / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvT6lE9lxJfo"
   },
   "source": [
    "## Group Specific Processing\n",
    "\n",
    "A common scenario is applying a function to a specific group of data. By group of data I mean a subset of the data that is the same based on a criterion. \n",
    "\n",
    "The `groupby()` `DataFrame` method is used to group rows of data by one or more of the column entries . The `groupby()` method accepts the parameter `by` which specifies how you want to group the rows of the calling `DataFrame`. `by` can be a single column label, a list of column lables, or a callable function. The method will return a `pandas` `GroupBy` object, an object we have not seen before. This object has certain attributes and methods that will be useful to us. In this chapter we will only cover the case of setting the `by` parameter of the `groupby()` method to a single column entry, if you are interested you can read more about the method [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html). \n",
    "\n",
    "If `by` is a sinlge label then the calling `DataFrame` will be grouped by the values in the column with the passed label, i.e. every entry with the same value in the specified column will be in the same group. For example, let us group the `spending_df` `DataFrame` by the values in the `specialty` column and save the returned `GroupBy` object to the variable we will call `spending_by_specialty`. To do this we use the following code.\n",
    "\n",
    "```python\n",
    ">>> spending_by_specialty = spending_df.groupby('specialty')\n",
    "```\n",
    "\n",
    "`GroupBy` objects have a handy method called `get_group()`, which returns all the entries of a specified group as a `DataFrame`. The `get_group()` method will take a positional argument that is the name of the group to access. Then the method returns a `DataFrame`, which is a subset of the initial `DataFrame` used to instantiate the `GroupBy` object. The entries of the returned `DataFrame` are all those entries in the column specified by the `by` parameter in the original `groupby()` call that match the name used in the `get_group()` call.\n",
    "\n",
    "Continuing with the example of the `spending_by_specialty` `GroupBy` object, let us see how we would retrieve the group of rows from the `spending_df` `DataFrame` whos entries in the `specialty` column were all the same value of 'CARDIOLOGY'. This group will conviently have the name 'CARDIOLOGY', thus when we use the `get_group` method we will simply pass the value 'CARDIOOGY'.\n",
    "\n",
    "```python\n",
    ">>> spending_by_specialty.get_group(\"CARDIOLOGY\")\n",
    "            doctor_id     specialty     medication                nb_beneficiaries  spending\n",
    "unique_id                                                                          \n",
    "VE177644\t1013915552\tCARDIOLOGY\tESOMEPRAZOLE MAGNESIUM\t30\t            10604.67\n",
    "BZ839028\t1750382313\tCARDIOLOGY\tPOTASSIUM CHLORIDE\t    44\t            916.65\n",
    "LC673466\t1619181427\tCARDIOLOGY\tPRAVASTATIN SODIUM\t    11\t            591.50\n",
    "HI410789\t1801882386\tCARDIOLOGY\tMETOPROLOL TARTRATE\t   305\t           2065.75\n",
    "SK725155\t1568469666\tCARDIOLOGY\tVERAPAMIL HCL\t         50\t            848.85\n",
    "```\n",
    "\n",
    "The example above returns all the entries of the  \"CARDIOLOGY\" group, i.e. all the entries from the original  `DataFrame` whos entries in the `specialty` column is \"CARDIOLOGY\", organized into a new `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_XL90pN1Xsc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doctor_id</th>\n",
       "      <th>specialty</th>\n",
       "      <th>medication</th>\n",
       "      <th>nb_beneficiaries</th>\n",
       "      <th>spending</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VE177644</th>\n",
       "      <td>1013915552</td>\n",
       "      <td>CARDIOLOGY</td>\n",
       "      <td>ESOMEPRAZOLE MAGNESIUM</td>\n",
       "      <td>30</td>\n",
       "      <td>10604.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BZ839028</th>\n",
       "      <td>1750382313</td>\n",
       "      <td>CARDIOLOGY</td>\n",
       "      <td>POTASSIUM CHLORIDE</td>\n",
       "      <td>44</td>\n",
       "      <td>916.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LC673466</th>\n",
       "      <td>1619181427</td>\n",
       "      <td>CARDIOLOGY</td>\n",
       "      <td>PRAVASTATIN SODIUM</td>\n",
       "      <td>11</td>\n",
       "      <td>591.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HI410789</th>\n",
       "      <td>1801882386</td>\n",
       "      <td>CARDIOLOGY</td>\n",
       "      <td>METOPROLOL TARTRATE</td>\n",
       "      <td>305</td>\n",
       "      <td>2065.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK725155</th>\n",
       "      <td>1568469666</td>\n",
       "      <td>CARDIOLOGY</td>\n",
       "      <td>VERAPAMIL HCL</td>\n",
       "      <td>50</td>\n",
       "      <td>848.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            doctor_id   specialty              medication  nb_beneficiaries  \\\n",
       "unique_id                                                                     \n",
       "VE177644   1013915552  CARDIOLOGY  ESOMEPRAZOLE MAGNESIUM                30   \n",
       "BZ839028   1750382313  CARDIOLOGY      POTASSIUM CHLORIDE                44   \n",
       "LC673466   1619181427  CARDIOLOGY      PRAVASTATIN SODIUM                11   \n",
       "HI410789   1801882386  CARDIOLOGY     METOPROLOL TARTRATE               305   \n",
       "SK725155   1568469666  CARDIOLOGY           VERAPAMIL HCL                50   \n",
       "\n",
       "           spending  \n",
       "unique_id            \n",
       "VE177644   10604.67  \n",
       "BZ839028     916.65  \n",
       "LC673466     591.50  \n",
       "HI410789    2065.75  \n",
       "SK725155     848.85  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spending_by_specialty = spending_df.groupby('specialty')\n",
    "spending_by_specialty.get_group(\"CARDIOLOGY\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HlMI5-EJUeFg"
   },
   "source": [
    "# Exercise 6.1: Group Specific Processing\n",
    "\n",
    "Which of the following options will correctly group data in `HNL_flights_df` by the entries in the `ORIGIN_AIRPORT` column and save the results in a `GroupBy` object, `HNL_flights_by_origin`?\n",
    "\n",
    "A:\n",
    "```python\n",
    "HNL_flights_by_origin = HNL_flights_df.groupby('ORIGIN_AIRPORT')\n",
    "```\n",
    "\n",
    "B:\n",
    "```python\n",
    "HNL_flights_df.groupby('ORIGIN_AIRPORT', inplace=True)\n",
    "```\n",
    "\n",
    "C:\n",
    "```python\n",
    "HNL_flights_by_origin.groupby('ORIGIN_AIRPORT')\n",
    "```\n",
    "\n",
    "D:\n",
    "```python\n",
    "HNL_flights_by_origin = pd.groupby(HNL_flights_df['ORIGIN_AIRPORT'])\n",
    "```\n",
    "\n",
    "*Hint: Feel free to use the code cell below to try these commands out. For the incorrect options, make note of what is going wrong and or what errors are being thrown.*\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Building on the first part of this exercise, which of the following lines of code will extract the subset, or group, of data in `HNL_flights_df` that all have a common `ORIGIN_AIRPORT` value of `LAX` and save the result into the `DataFrame: LAX_to_HNL_df`?\n",
    "\n",
    "\n",
    "A:\n",
    "```python\n",
    "LAX_to_HNL_df = HNL_flights_by_origin.get_group(ORIGIN_AIRPORT = 'LAX')\n",
    "```\n",
    "\n",
    "B:\n",
    "```python\n",
    "LAX_to_HNL_df = HNL_flights_by_origin.loc[:,'LAX']\n",
    "```\n",
    "\n",
    "C:\n",
    "```python\n",
    "LAX_to_HNL_df = HNL_flights_by_origin['LAX']\n",
    "```\n",
    "\n",
    "D:\n",
    "```python\n",
    "LAX_to_HNL_df = HNL_flights_by_origin.get_group('LAX')\n",
    "```\n",
    "\n",
    "*Hint: Feel free to use the code cell below to try these commands out. For the incorrect options, make note of what is going wrong and or what errors are being thrown.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iRujZDErXa_y"
   },
   "outputs": [],
   "source": [
    "# Exercise 6.1 Scratch code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGMMA2T9xRTP"
   },
   "source": [
    "### Split Apply Combine\n",
    "\n",
    "Getting groups can be easily implemented using subsetting. For instance, we could have obtained the \"CARDIOLOGY\" group of the `spending_df` `DataFrame` by subsetting `spending_df` with the boolean `Series` returned from the following operation\n",
    "\n",
    "```python\n",
    "spending_df[spending_df.loc[:, \"specialty\"] == \"CARDIOLOGY\"].head()\n",
    "            doctor_id     specialty     medication                nb_beneficiaries  spending\n",
    "unique_id                                                                          \n",
    "VE177644\t1013915552\tCARDIOLOGY\tESOMEPRAZOLE MAGNESIUM\t30\t            10604.67\n",
    "BZ839028\t1750382313\tCARDIOLOGY\tPOTASSIUM CHLORIDE\t    44\t            916.65\n",
    "LC673466\t1619181427\tCARDIOLOGY\tPRAVASTATIN SODIUM\t    11\t            591.50\n",
    "HI410789\t1801882386\tCARDIOLOGY\tMETOPROLOL TARTRATE\t   305\t           2065.75\n",
    "SK725155\t1568469666\tCARDIOLOGY\tVERAPAMIL HCL\t         50\t            848.85\n",
    "```\n",
    "\n",
    "We see in the above example that the returned `DataFrame` is exactly the same as the result we saw in the previous cell introducing `groupby()` and `get_group()`. So why use `GroupBy` objects anyway?\n",
    "\n",
    "An ideal usage of `groupby()`, and the resulting `GroupBy object`, will apply operations to **each** group independently. Furthermore, `GroupBy` objects are intended to be applied in the context of the data processing paradigm called \"split-apply-combine\"\n",
    "\n",
    "* **Split** the data into chunks defined using one or more columns\n",
    "* **Apply** some operation on the chunks generated. \n",
    "* **Combine** the results of the applied operation into a new `DataFrame`\n",
    "\n",
    "For instance, suppose we wanted to compute the total spending by `specialty`and save the result to a news `DataFrame`, the steps we would need to take are:\n",
    "\n",
    "1. Split the data by `specialty`, i.e. `groupby('specialty')`\n",
    "2. Apply the `sum()` method to the `spending` column for each group\n",
    "3. Combine the results from each group into a new `DataFrame`\n",
    "\n",
    "![](images/split_apply_combine_example.png)\n",
    "\n",
    "So rather than manually subsetting each group and then applying the desired operation we could automate this workflow using the helpful `GroupBy` methods implemented by `pandas` to save ourselves some time and effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y5hv9GKf5RMw"
   },
   "source": [
    "#### The 3 Classes of Opearations on Groups\n",
    "\n",
    "There are 3 classes of split-apply-combine operations that can be applied to group data.\n",
    "\n",
    "\n",
    "1. __Aggregations__ generate a single value for each group\n",
    "  \n",
    "2.  __Transformations__ convert the data and generate a group of the same size as the original group.\n",
    "\n",
    "3.  __Filters__ retain or discard a group based on group-specific boolean computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-fBi2KE7_Ipb"
   },
   "source": [
    "<img src='images/aggregate.png' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FjY1ne0W_IeZ"
   },
   "source": [
    "<img src='images/transform.png' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q7p2JxIT_ISo"
   },
   "source": [
    "<img src='images/filter.png' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YtvBOY2DxxoG"
   },
   "source": [
    "#### Aggregate\n",
    "\n",
    "__Aggregations__ aggregate the data in each group, i.e., they reduce the data to a single value. This includes, for instance, computing group sums, means, maximums, minimums, _etc_. Some of the interesting/important summary aggregation methods of `GroupBy`  objects are:\n",
    "\n",
    "|Methods| Decription|\n",
    "|:----------|:----------------|\n",
    "| `mean`, `median` | Computes the mean and the median in each group| \n",
    "| `min` , `max` | computes the min and max in each group| \n",
    "| `size` | computes the number of values in each group| \n",
    "\n",
    "When one of these methods are called by the `GroupBy` object, they are applied to each group individually and then the group is combined into a new `DataFrame`.\n",
    "\n",
    "For example suppose we wanted to group by `specialty`, apply the `sum()` method to calculate the total `spending` and total `nb_beneficiaries`, and then combine the results into a new `DataFrame` which holds the total `spending` and `nb_beneficiaries` by `specialty`. We could achieve this by first splitting the data using the `groupby()` `DataFrame` method to obtain a new `GroupBy` object, we will call it `spending_by_specialty`. Then we could apply and combine using the `GroupBy` object's `sum()` method.\n",
    "\n",
    "```python\n",
    ">>> spending_by_specialty = spending_df.groupby('specialty')\n",
    ">>> spending_by_specialty.sum().head(n=3)\n",
    "                      doctor_id\t  nb_beneficiaries\tspending\n",
    "\n",
    "ADDICTION MEDICINE\t4736204585\t 74\t              920.06\n",
    "ALLERGY/IMMUNOLOGY\t34975929476\t1063\t            189174.06\n",
    "ANESTHESIOLOGY\t    47888385098\t1673\t            142804.73\n",
    "```\n",
    "\n",
    "We see from the above example that the `GroupBy` `sum()` method returns a `DataFrame` with an index labeling the group that the row entry corresponds to and entries telling us the total `spending` and total `nb_beneficiaries`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSD3S1kcvXIh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_beneficiaries</th>\n",
       "      <th>spending</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specialty</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADDICTION MEDICINE</th>\n",
       "      <td>74</td>\n",
       "      <td>920.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLERGY/IMMUNOLOGY</th>\n",
       "      <td>1063</td>\n",
       "      <td>189174.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANESTHESIOLOGY</th>\n",
       "      <td>1673</td>\n",
       "      <td>142804.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    nb_beneficiaries   spending\n",
       "specialty                                      \n",
       "ADDICTION MEDICINE                74     920.06\n",
       "ALLERGY/IMMUNOLOGY              1063  189174.06\n",
       "ANESTHESIOLOGY                  1673  142804.73"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spending_df.groupby('specialty').sum().head(n=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODHG9if8ycUR"
   },
   "source": [
    "##### Aggregate Continued\n",
    "\n",
    "As discussed in the previous cell, `pandas` has implemented for us the most common aggregate methods for us, like `sum()` and `mean()`, but sometimes our data requires unique processing. The `GroupBy` method `agg()` can be used where complex or custom aggregation logic is required. The method `agg()` will take a function and use it to aggregate the group in the same way that we saw `sum()` do in the previous cell. The function passed must take a `DataFrame` as an argument, and that passed `DataFrame` will be each group of the calling `GroupBy` object.\n",
    "\n",
    "For example, suppose we wanted to find the total spending by specialty in Canadian dollars. We can define a function called `sum_spending_CAD()` to return the sum of the spending of a group in Canadian Dollars. Then we can create a new `GroupBy` object, call it `spending_by_specialty`, using a subset of the `spending_df` `DataFrame` only containing the `specialty` and `spending` columns. Lastly, we can can call `agg()` with the `spending_by_specialty` `GroupBy` object and pass it the `sum_spending_CAD` function.\n",
    "\n",
    "```python\n",
    ">>> def sum_spending_CAD(x):\n",
    ">>>    return x.sum() * 1.33\n",
    ">>> spending_by_specialty = spending_df.loc[:, ['specialty', 'spending']].groupby('specialty')\n",
    ">>> spending_by_specialty.agg(sum_spending_CAD).head(n=3)\n",
    "\t                  spending\n",
    "ADDICTION MEDICINE\t1186.8774\n",
    "ALLERGY/IMMUNOLOGY\t244034.5374\n",
    "ANESTHESIOLOGY\t    184218.1017\n",
    "```\n",
    "\n",
    "We see in the above example that the result is a new `DataFrame` with the unique `speciality` values as the index and values corresponding the sum total of the spending by specialty in Candian dollars.\n",
    "\n",
    "To customize group specific processing even further `agg()` can also take a dictionary of functions to aggregate on. The dictionary should be the name of a column of the group and the value a callable function that will take a `Series`. \n",
    "\n",
    "For example, suppose we wanted to create a new `DataFrame` that tells us the total `nb_beneficiaries` and the max `spending` by specialty from `spending_df`. To do this we would first `groupby()` `specialty` and then call `agg()` with the new `GroupBy` object, passing it the dictionary: `{'nb_beneficiaries' :sum,'spending' : max}`, which specifies that we want to sum the `nb_beneficiaries` column and find the max of the `spending` column.\n",
    "\n",
    "```python \n",
    ">>> spending_by_specialty = spending_df.groupby('specialty')\n",
    ">>> spending_by_specialty.agg({'nb_beneficiaries' :sum,\n",
    "                                 'spending' : max}).head(n=3)\n",
    "\t                  nb_beneficiaries\tspending\n",
    "ADDICTION MEDICINE\t74\t              817.88\n",
    "ALLERGY/IMMUNOLOGY\t1063\t            52389.61\n",
    "ANESTHESIOLOGY\t    1673\t            34073.91\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3gg8vN5AzQ3G"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spending</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specialty</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADDICTION MEDICINE</th>\n",
       "      <td>1186.8774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLERGY/IMMUNOLOGY</th>\n",
       "      <td>244034.5374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANESTHESIOLOGY</th>\n",
       "      <td>184218.1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       spending\n",
       "specialty                      \n",
       "ADDICTION MEDICINE    1186.8774\n",
       "ALLERGY/IMMUNOLOGY  244034.5374\n",
       "ANESTHESIOLOGY      184218.1017"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_spending_CAD(x):\n",
    "   return x.sum() * 1.29\n",
    "spending_by_specialty = spending_df.loc[:, ['specialty', 'spending']].groupby('specialty')\n",
    "spending_by_specialty.agg(sum_spending_CAD).head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_beneficiaries</th>\n",
       "      <th>spending</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specialty</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADDICTION MEDICINE</th>\n",
       "      <td>74</td>\n",
       "      <td>817.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLERGY/IMMUNOLOGY</th>\n",
       "      <td>1063</td>\n",
       "      <td>52389.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANESTHESIOLOGY</th>\n",
       "      <td>1673</td>\n",
       "      <td>34073.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    nb_beneficiaries  spending\n",
       "specialty                                     \n",
       "ADDICTION MEDICINE                74    817.88\n",
       "ALLERGY/IMMUNOLOGY              1063  52389.61\n",
       "ANESTHESIOLOGY                  1673  34073.91"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spending_by_specialty = spending_df.groupby('specialty')\n",
    "spending_by_specialty.agg({'nb_beneficiaries' :sum,\n",
    "                           'spending' : max}).head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uebGVP6KV0tc"
   },
   "source": [
    "# Exercise 6.2: Aggregate\n",
    "\n",
    "Using the code cell below, create a new `DataFrame` named `delay_by_origin` that is indexed by the unique origin airports in `HNL_flights_df` and contains the median departure and arrival delays for groups of flights with common origin airports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOWb2e3iYPRX"
   },
   "outputs": [],
   "source": [
    "# Type your solution to Exercise 6.2 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhxoqxboyBdG"
   },
   "source": [
    "#### Transform\n",
    "\n",
    " __Transformations__ change the data in a way that is group-specific. As opposed to aggregations, which reduce the data into a single value, transformations modify the data but don't change the shape of the groups\n",
    "\n",
    "The example below computes the percent contribution of each entry to each specialty by applying a transformation that normalizes the entry's spending over the total spending in that specialty. \n",
    "\n",
    "![](images/transform_spending.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWc7L9-U1BXr"
   },
   "source": [
    "##### Transform Continued 1\n",
    "\n",
    "Applying a transformation is done using the `transform()` `GroupBy` method. The `transform()` method takes as input a function name, which it calls on each group of the `GroupBy` object. The function passed to `transform()` must take a `DataFrame`, which will be a group of the calling `GroupBy` object. \n",
    "\n",
    "For example, suppose we wanted to transform the `spending` column of the `spending_df` `DataFrame` to hold the percentage of the total spending by specialty that rows makes up.  First, we would define a function which will take a `DataFrame` and calculate the the percentage of the total each entry takes up. Then we will create a new `GroupBy` object groupded by `specialty` from a subset of `spending_df` that only has the columns `spending` and `specialty`. Then we will call transform passing it the name of our defined function. \n",
    "\n",
    "```python\n",
    ">>> def my_function(x):\n",
    ">>>    return (x   / x.sum() ) * 100\n",
    "  \n",
    ">>> spending_by_specialty = spending_df.loc[:, ['specialty', 'spending']].groupby('specialty')\n",
    " \n",
    ">>> spending_by_specialty.transform(my_function)[spending_df['specialty'] == \"CARDIOLOGY\"].head()\n",
    "\n",
    "           spending\n",
    "unique_id           \n",
    "VE177644   0.553541\n",
    "BZ839028   0.047847\n",
    "LC673466   0.030875\n",
    "HI410789   0.107828\n",
    "SK725155   0.044308\n",
    "```\n",
    "\n",
    "We see that the result is a new `DataFrame` with an index matching that of the original `DataFrame` used to initialize the `GroupBy` object. This is different than the aggregation example because aggregation reduces the group to a single value, while transformation maintains the shape of the calling `DataFrame`.\n",
    "\n",
    "Let us save these results into a new column in `spending_df` called `spending_pct`.\n",
    "\n",
    "```python\n",
    ">>> spending_df['spending_pct'] = spending_by_specialty.transform(my_function)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e64Euy5R1U-u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           spending\n",
      "unique_id          \n",
      "VE177644   0.553541\n",
      "BZ839028   0.047847\n",
      "LC673466   0.030875\n",
      "HI410789   0.107828\n",
      "SK725155   0.044308\n"
     ]
    }
   ],
   "source": [
    "def my_function(x):\n",
    "    return (x   / x.sum() ) * 100\n",
    "\n",
    "spending_by_specialty = spending_df.loc[:, ['specialty', 'spending']].groupby('specialty')\n",
    "\n",
    "print(spending_by_specialty.transform(my_function)[spending_df['specialty'] == \"CARDIOLOGY\"].head())\n",
    "\n",
    "spending_df['spending_pct'] = spending_by_specialty.transform(my_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_4-cf8sMd8Z"
   },
   "source": [
    "##### Transform Continued 2\n",
    "\n",
    "Suppose we wanted to see the percent spending by `drug` and `specialty`. One solution to achieve this would be to group on both the `specialty` and the `medication` columns and then sum the `spending_pct` that was computed previously.\n",
    "\n",
    "```python\n",
    ">>> medication_spending_pct =  spending_df.loc[:,['specialty', 'medication', 'spending_pct']].groupby([\"specialty\", \"medication\"]).sum()\n",
    ">>> medication_spending_pct.head(n=3)\n",
    "                                   spending_pct\n",
    "specialty  medication                        \n",
    "CARDIOLOGY ATORVASTATIN CALCIUM     50.791475\n",
    "           PANTOPRAZOLE SODIUM      29.960547\n",
    "           SIMVASTATIN              14.302612\n",
    "```\n",
    "\n",
    "Notice that since we are grouping on two columns, the resulting index of `medication_spending_pct` also contains two columns. Now we can sort first on the values in the `specialty` column, so that all the entries with a common specialty are clustered together, and then on the values in the `spending_pct` columns.\n",
    "\n",
    "```python\n",
    ">>> medication_spending_pct.sort_values([\"specialty\", \"spending_pct\"], ascending=[True, False]).head(n=)\n",
    "\t\t                                      spending_pct\n",
    "specialty\t         medication\t\n",
    "ADDICTION MEDICINE\tBUSPIRONE HCL            88.894203\n",
    "                      LAMOTRIGINE              8.979849\n",
    "                      LORAZEPAM\t            2.125948\n",
    "ALLERGY/IMMUNOLOGY\tFLUTICASONE/SALMETEROL   41.898900\n",
    "                      MOMETASONE FUROATE\t   18.141250\n",
    "```\n",
    "\n",
    "Each row in the resulting `DataFrame` tells us the percent of spending for each unique medication and specialty combination.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwPpV8mJNgrQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>spending_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specialty</th>\n",
       "      <th>medication</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ADDICTION MEDICINE</th>\n",
       "      <th>BUSPIRONE HCL</th>\n",
       "      <td>88.894203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAMOTRIGINE</th>\n",
       "      <td>8.979849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LORAZEPAM</th>\n",
       "      <td>2.125948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ALLERGY/IMMUNOLOGY</th>\n",
       "      <th>FLUTICASONE/SALMETEROL</th>\n",
       "      <td>41.898900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOMETASONE FUROATE</th>\n",
       "      <td>18.141250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           spending_pct\n",
       "specialty          medication                          \n",
       "ADDICTION MEDICINE BUSPIRONE HCL              88.894203\n",
       "                   LAMOTRIGINE                 8.979849\n",
       "                   LORAZEPAM                   2.125948\n",
       "ALLERGY/IMMUNOLOGY FLUTICASONE/SALMETEROL     41.898900\n",
       "                   MOMETASONE FUROATE         18.141250"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medication_spending_pct = spending_df.loc[:, ['specialty', 'medication', 'spending_pct']].groupby([\"specialty\", \"medication\"]).sum()\n",
    "medication_spending_pct.sort_values([\"specialty\", \"spending_pct\"], ascending=[True, False]).head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "py-Gy0np6uq1"
   },
   "source": [
    "# Exercise 6.3: Transform\n",
    "\n",
    "Using the code cell below, \n",
    "* create a new `DataFrame` named `distance_and_day_df` that is a subset of `HNL_flights_df` containing only the `DAY` and `DISTANCE` columns. \n",
    "* Group `distance_and_day_df` by the `DAY` column and save the resulting `GroupBy` object in the variable `distance_by_day`. \n",
    "* Transfrom the `DISTANCE` column for each flight by calculating the percentage of the total distance by day the flight took. Save the result in a new column of  `HNL_flights_df` named `DISTANCE_PCT`. Use the function pre-defined in the cell to perform the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9B7K0AhEBMRF"
   },
   "outputs": [],
   "source": [
    "def percent_of_total(x):\n",
    "  return (x   / x.sum() ) * 100\n",
    "\n",
    "# Type your solution to Exercise 6.3 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WKk2opbYyFHx"
   },
   "source": [
    "#### Filter\n",
    "\n",
    " __Filtering__  a group consists of dropping or retaining groups in a way that depends on a group-specific computation that returns `True` or `False`. Groups that are retained will be left unmodified. For instance, we can filter specialties from `spending_df` that don't have enough entries or for which the mean `spending` is below a certain threshold.\n",
    "\n",
    "Filtering a group is done using the `GroupBy` method `filter()`. The method `filter()` takes as input a function name, which it calls on each group of the `GroupBy` object. The function must return either `True` or `False` and groups for which the function returns `False` are dropped. The resulting `DataFrame` will have entries in the same order as the original `DataFrame`.\n",
    "\n",
    "Suppose we want to filter out the specialties that are low spending, i.e. we want to filter out the specialties for which the total spending is less than some defined threshold, let say $\\$5,000,000$. To do this we can define a function named `filter_on_spending()`. The defined function will take a `DataFrame`, determine whether the sum total of the `spending` column in that `DataFrame` is greater than 5000000, and then return `True` if it is or `False` if not. \n",
    "\n",
    "Then, to apply the filter on `spending_df`, we first subset the `DataFrame` so that only the columns `specialty` and `spending` are remaining and then group by `specialty`. Then the `GroupBy filter()` method can be called with the `filter_on_spending()` function passed as an argument. We can save the results into a new `DataFrame` named `high_spending_df`. Then to see which specialties surpassed the $\\$5,000,000$ total spending threshold we can print the unique values in the `specialty` column of `high_spending_df`.\n",
    "\n",
    "```python\n",
    ">>> def filter_on_spending(x):\n",
    ">>>     return x['spending'].sum() > 5000000\n",
    "\n",
    ">>> high_spending_df = spending_df[[\"specialty\", 'spending']].groupby('specialty').filter(filter_on_spending)\n",
    "\n",
    ">>> high_spending_df['specialty'].unique()\n",
    "array(['FAMILY PRACTICE', 'INTERNAL MEDICINE'], dtype=object)\n",
    "```\n",
    "We see that only two specialties passed the threshold of total spending greater than $\\$5,000,000$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8e9Y1zLSOaTT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FAMILY PRACTICE', 'INTERNAL MEDICINE'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_on_spending(x):\n",
    "     return x['spending'].sum() > 5000000\n",
    "\n",
    "high_spending_df = spending_df[[\"specialty\", 'spending']].groupby('specialty').filter(filter_on_spending)\n",
    "\n",
    "high_spending_df['specialty'].unique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39wMYAWQGsdI"
   },
   "source": [
    "# Exercise 6.4: Filter\n",
    "\n",
    "Using the code cell below, \n",
    "* Group `HNL_flights_df` by the `DAY` column and save the resulting `GroupBy` object in the variable `hnl_flights_by_day`. \n",
    "* Filter the flights by determining if the `ARRIVAL_DELAY` of the day was net positive, i.e. if there was a positive total delay for a day keep the flights, otherwise filter them out. Save the resulting `DataFrame` into the variable `HNL_flights_delayed_days_df`. Use the function pre-defined in the cell to perform the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFhrY6rlIs5g"
   },
   "outputs": [],
   "source": [
    "def net_postive_arrival_delay(x):\n",
    "  return  x.ARRIVAL_DELAY.sum() > 0\n",
    "\n",
    "# Type your solution to Exercise 6.4 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSrZmsDlyOWj"
   },
   "source": [
    "#### Thinning Data and The Flexible `apply()`  GroupBy Method\n",
    "\n",
    "`pandas` provides a few built-in `GroupBy` methods for thinning the data including `nlargest()`, `nsmallest()`, and more. An example usage of `nlargest()`, a thinning method, would be grouping a subset of `spending_df` which contains only the `spending` and `specialty` columns by `specialty` and then obtaining the 2 largest of each specialty. The result will be a new `DataFrame` with only the top 2 spenders from each unique specialty.\n",
    "\n",
    "```python\n",
    ">>> spending_by_specialty = spending_df.loc[:,['specialty', 'spending']].groupby('specialty')\n",
    ">>> spending_by_specialty['spending'].nlargest(2).head(n=4)\n",
    "specialty          unique_id\n",
    "ADDICTION MEDICINE  GJ278932       817.88\n",
    "                    VG585760        82.62\n",
    "ALLERGY/IMMUNOLOGY  XY715196     52389.61\n",
    "                    DL492570     29153.71\n",
    "Name: spending, dtype: float64\n",
    "```\n",
    "    \n",
    "Though `pandas` has the more common and basic aggregation, transformation, and thinning methods implmented for us, they could not possibly cover all cases. Therefore cases that do not fit into any one of these categories may be carried out by using the more flexible `apply() GroupBy` method. `apply()` takes as input a function name, which it calls on each group of the calling `GroupBy` object.\n",
    "\n",
    "For example suppose we wanted to thin our dataset so that there are only 50% of each specialty represented. To do this we can define a new function, we will call it, `sample_50p`, and this function will utilize the `sample()` `DataFrame` method. The `sample()` `DataFrame` method will take a parameter `frac` that specifies the fraction of the original `DataFrame` that is to be returned. We can then use the `apply()` method and pass it the name of our newly defined function to obtain a new `DataFrame` that is filtered at the group specific level. \n",
    "\n",
    "```python\n",
    ">>> def sample_50p(x):\n",
    ">>>    return x.sample(frac=0.5)\n",
    "    \n",
    ">>> spending_by_specialty = spending_df.loc[:,['specialty', 'spending', 'medication']].groupby('specialty')\n",
    ">>> spending_by_specialty.apply(sample_50p).head(n=3)\n",
    "\t\t                                   specialty\tspending\tmedication\n",
    "specialty\t         unique_id\t\t\t\n",
    "ADDICTION MEDICINE\tGJ278932\tADDICTION MEDICINE\t817.88\t  BUSPIRONE HCL\n",
    "                      TX420809\tADDICTION MEDICINE\t19.56\t   LORAZEPAM\n",
    "ALLERGY/IMMUNOLOGY\tEW891894\tALLERGY/IMMUNOLOGY\t12411.92\tDEXLANSOPRAZOLE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "specialty           unique_id\n",
       "ADDICTION MEDICINE  GJ278932       817.88\n",
       "                    VG585760        82.62\n",
       "ALLERGY/IMMUNOLOGY  XY715196     52389.61\n",
       "                    DL492570     29153.71\n",
       "Name: spending, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spending_by_specialty = spending_df.loc[:,['specialty', 'spending']].groupby('specialty')\n",
    "spending_by_specialty['spending'].nlargest(2).head(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzTzcosWUN0o"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>specialty</th>\n",
       "      <th>spending</th>\n",
       "      <th>medication</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specialty</th>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ADDICTION MEDICINE</th>\n",
       "      <th>GJ278932</th>\n",
       "      <td>ADDICTION MEDICINE</td>\n",
       "      <td>817.88</td>\n",
       "      <td>BUSPIRONE HCL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX420809</th>\n",
       "      <td>ADDICTION MEDICINE</td>\n",
       "      <td>19.56</td>\n",
       "      <td>LORAZEPAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLERGY/IMMUNOLOGY</th>\n",
       "      <th>EW891894</th>\n",
       "      <td>ALLERGY/IMMUNOLOGY</td>\n",
       "      <td>12411.92</td>\n",
       "      <td>DEXLANSOPRAZOLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       specialty  spending       medication\n",
       "specialty          unique_id                                               \n",
       "ADDICTION MEDICINE GJ278932   ADDICTION MEDICINE    817.88    BUSPIRONE HCL\n",
       "                   TX420809   ADDICTION MEDICINE     19.56        LORAZEPAM\n",
       "ALLERGY/IMMUNOLOGY EW891894   ALLERGY/IMMUNOLOGY  12411.92  DEXLANSOPRAZOLE"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_50p(x):\n",
    "  return x.sample(frac=0.5)\n",
    "spending_by_specialty = spending_df.loc[:,['specialty', 'spending', 'medication']].groupby('specialty')\n",
    "spending_by_specialty.apply(sample_50p).head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mmmDOqMUdTz"
   },
   "source": [
    "# Summary\n",
    "\n",
    "---\n",
    "\n",
    "**Function Application and Mapping**\n",
    "\n",
    "* **Global Processing**\n",
    "  * To apply a function to every row or column in a `DataFrame` we can use the `apply()` method\n",
    "  * To apply a function to every element in a `Series` we can use the `map()` method\n",
    "  * To apply a function to every element in a `DataFrame` we can use the `applymap()` method\n",
    "  \n",
    "* **Group Specific Processing**\n",
    "\n",
    "  * The `groupby()` method is used to group the data using values on one or more columns\n",
    "\n",
    "  * `groupby()` is often applied in the context of the data processing paradigm called \"split-apply-combine\"\n",
    "    * **Split**: you need to split the data into chunks defined using one or more columns\n",
    "    * **Apply**: apply some operation on the chunks generated. \n",
    "    * **Combine**: combine the results of the applied operation into a new `DataFrame`\n",
    "\n",
    "  * There are 3 common classes of split-apply-combine operations that can be applied to group data.\n",
    "\n",
    "    1. __Aggregations__ generate a single value for each group\n",
    "  \n",
    "    2.  __Transformations__ convert the data and generate a group of the same size as the original group.\n",
    "\n",
    "    3.  __Filters__ retain or discard a group based on group-specific boolean computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4_Data Preparation_and_Cleaning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
