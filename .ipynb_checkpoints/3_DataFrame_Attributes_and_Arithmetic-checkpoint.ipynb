{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HOM84FzyZ8RG"
   },
   "source": [
    "# `DataFrame` Attributes and Arithmetic \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "It is crucial to have a deep understanding of your data in order to draw meaningful insights from it. In this chapter we will see how to use the built in functionalities of `pandas` to begin exploring and transforming our data. This will help us identify patterns or potential flaws in our dataset and hopefully inspire or even answer some interesting questions.\n",
    "\n",
    "The structure of this chapter is as follows: We will start with preparing our environment and a review of the data set that we will be working with to illustrate new concepts and skills. Once we complete our preperation, we dive into the attributes and methods that can be used summarize your data. After that, we continue with learning about arithmetic and data alignment between `Series` and `DataFrames` by covering vectorization and broadcasting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_u2Qpd3q9jIq"
   },
   "source": [
    "# Preparing our Environment\n",
    "\n",
    "---\n",
    "\n",
    "In this chapter we will only be needing the pandas toolkit. We will be importing the library under the standard alias `pd`.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qLC2OZbAfhe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Wc-H5aBEZY0"
   },
   "source": [
    "# About the Data\n",
    "\n",
    "---\n",
    "\n",
    "To help us grasp the new content we will be covering in this chapter, we will again be using the data stored in the `'Data/spending_10k.csv'` file. This data is a subset of the complete dataset that is publicly available on the Centers for Medicare & Medicaid Services website ([`CMS` website](https://www.cms.gov/OpenPayments/Explore-the-Data/Dataset-Downloads.html)).  Here is a brief review of the data:\n",
    "\n",
    "| Column |Description|\n",
    "|:----------|-----------|\n",
    "| `unique_id`| A unique identifier for a Medicare claim to CMS |\n",
    "| `doctor_id` | The Unique Identifier of the doctor who <br/> prescribed the medicine  |\n",
    "| `specialty` | The specialty of the doctor who prescribed the medicine |\n",
    "| `medication` | The medication prescribed |\n",
    "| `nb_beneficiaries` | The number of beneficiaries the <br/> medicine was prescribed to  |\n",
    "| `spending` | The total cost of the medicine prescribed <br/>for the CMS |\n",
    "\n",
    "This file has a header containing the labels of the column names so we will leave the `pd.read_csv()` `header` parameter to its default setting when we read the file using `pd.read_csv()`. Let us also use the `unique_id` column as the index rather than a range of integers, so we will pass the name of the column, `unique_id`, to the `index_col` parameter of the `pd.read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7M6A85qTIW1M"
   },
   "outputs": [],
   "source": [
    "spending_df = pd.read_csv('Data/spending_10k.csv', index_col='unique_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tTtPTkaXjg7e"
   },
   "source": [
    "## Exercise 3.0: Importing the Honolulu Flights Data Set\n",
    "\n",
    "For some of the exercises in this chapter we will be working with a data set containing information about all the arriving and departing flights in and out of the Honolulu aiport, HNL, on the Island of Oahu in December 2015. \n",
    "\n",
    "This data set contains the following columns:\n",
    "\n",
    "| Column |Description|\n",
    "|:----------|-----------|\n",
    "| `YEAR` | The year of the flight  |\n",
    "| `MONTH` |  The month of the flight |\n",
    "| `DAY` |  The day of the flight |\n",
    "| `DAY_OF_WEEK` |  The day of the week of the flight |\n",
    "| `FLIGHT_NUMBER` |  The flight number of the flight |\n",
    "| `ORIGIN_AIRPORT` |  The origin airport of the flight  |\n",
    "| `DESTINATION_AIRPORT` |  The destination airport of the flight |\n",
    "| `DEPARTURE_DELAY` |  The departure delay of the flight  |\n",
    "| `DISTANCE` |  The distance of the flight in miles |\n",
    "| `AIR_TIME` |  The flight time without taxiing in minutes |\n",
    "| `ARRIVAL_DELAY` |  The arrival delay of the flight  |\n",
    "\n",
    "Please run the following code cell which will parse the 'honolulu_flights.csv' file, and build the `HNL_flights_df DataFrame` before trying the exercises in this chapter related to this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVOqzGVdpbz1"
   },
   "outputs": [],
   "source": [
    "HNL_flights_df = pd.read_csv('Data/honolulu_flights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j3ggq3qsgUaE"
   },
   "source": [
    "# Summarizing Your Data\n",
    "\n",
    "---\n",
    "\n",
    "It is often useful to quickly explore some of the descriptive attributes and statistics of the dataset that you are working with. For instance, the shape and datatypes of the `DataFrame`, and the range, mean, standard deviation, etc. of the rows or columns. You may find interesting patterns or possibly catch errors in your dataset this way. As we will see, accessing these attributes and computing the descriptive statistics is easy with `pandas`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfNSyBGVhAcC"
   },
   "source": [
    "## Attributes\n",
    "As was mentioned in Chapter 1: *Introduction to pandas Data Structures* , `DataFrames` have a number of attributes associated with them. With respect to exploring your dataset, perhaps the 3 most useful attributes are summarized in the table below:\n",
    "\n",
    "| Attribute |Description|\n",
    "|:----------|-----------|\n",
    "| `shape`| Return a tuple representing the dimensionality of the DataFrame. |\n",
    "| `size` | Return an int representing the number of elements in this object.  |\n",
    "| `dtypes` | Return the dtypes in the DataFrame. |\n",
    "\n",
    "In `Python`, you can access an object’s attribute using the syntax `ObjectName.attributeName`. For instance, if our `DataFrame` is named `df` and our attribute is `shape`, `df.shape`will return the shape attribute of our `DataFrame`.\n",
    "\n",
    "A list of all the `DataFrame` attributes can be found at the [`pandas` Documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ah77ttOkQHst"
   },
   "source": [
    "### Inspecting Data Types\n",
    "\n",
    "We have seen and have been using both `shape` and `size` and their relevance is clear, but it is not so obvious why we should be concerned with the data types of the `DataFrame`. One reason is that some methods can only work on specific data types.  For example, it would be unreasonable to compute the mean of the column `specialty` since the data type of `specialty` does not lend itself to being averaged.\n",
    "\n",
    "`DataFrames` maintain an additional `Series`, named `dtypes`, which holds the data types in the `DataFrame` by column. The `dtypes` `Series` of a `DataFrame` allows `pandas` to instantly evaluate which methods can be applied to which columns. \n",
    "\n",
    "Let us look at the `dtypes` attribute of the `spending_df` `DataFrame`.\n",
    "\n",
    "```python\n",
    ">>> spending_df.dtypes\n",
    "doctor_id             int64\n",
    "specialty            object\n",
    "medication           object\n",
    "nb_beneficiaries      int64\n",
    "spending            float64\n",
    "dtype: object\n",
    "```\n",
    "\n",
    "We see that the `dtypes` attribute of the `spending_df` `DataFrame` is a `Series` with an `index` equivalent to the `columns` attribute of the `spending_df` `DataFrame`, and values which specify the data types of the entries in the corresponding column of the `DataFrame`.\n",
    "\n",
    "![](images/dtypes.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyQuvWX2QEfj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doctor_id             int64\n",
       "specialty            object\n",
       "medication           object\n",
       "nb_beneficiaries      int64\n",
       "spending            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spending_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p8UmxUdzNe3f"
   },
   "source": [
    "## Exercise 3.1: Attributes\n",
    "\n",
    "Which of the following lines of code will give the number of rows and columns, i.e. the shape attribute, of  the `HNL_flights_df DataFrame`?  Please note that the output should be: (7975, 11).\n",
    "\n",
    "A:\n",
    "```python\n",
    "HNL_flights_df.size\n",
    "```\n",
    "\n",
    "B: \n",
    "```python\n",
    "HNL_flights_df.shape\n",
    "```\n",
    "\n",
    "C: \n",
    "```python\n",
    "HNL_flights_df.shape()\n",
    "```\n",
    "\n",
    "D: \n",
    "```python\n",
    "pd.shape(HNL_flights_df)\n",
    "```\n",
    "\n",
    "Hint: Feel free to use the code cell below to try these commands out. For the incorrect options, make note of what is going wrong and or what errors are being thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTbr4EU2VhUS"
   },
   "outputs": [],
   "source": [
    "# Exercise 3.1 Scratch Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpYXMxxvhTUy"
   },
   "source": [
    "## Methods\n",
    "\n",
    "Please recall that in `Python` a method is a function that is accessible via an object instance, such as a `DataFrame`. The syntax for using a method is similar to accessing an attribute: `ObjectName.methodName()`. `DataFrames` have many built-in methods to summarize our data. The methods we will be most interested in to explore our data set are:\n",
    "\n",
    "| Method|Description|\n",
    "|:----------|-----------|\n",
    "| `head()`| Return the first n rows. |\n",
    "| `tail()` | Return the last n rows. |\n",
    "| `min()`, `max()` | Computes the numeric (for numeric value) or alphanumeric (for object values) row-wise min, max in a Series or DataFrame.|\n",
    "| `sum()`, `mean()`, `std()`, `var()`   | Computes the row-wise sum, mean, standard deviation and variance in a `Series` or DataFrame.|\n",
    "|`nlargest()`|\tReturn the first n rows of the `Series` or `DataFrame`, ordered by the spceified columns in descending order. |\n",
    "| `count()` |  Returns the number of non-NaN values in the in a `Series` or `DataFrame`. |\n",
    "| `value_counts()` |  Returns the frequency for each value in the `Series`. |\n",
    "| `describe()` | Computes row-wise statistics. |\n",
    "\n",
    "We will be covering when and how to use each of the methods described in the table above.\n",
    "\n",
    "If interested, a list and description of all the `DataFrame` methods may be found at the [pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0t1p9XjxtSTl"
   },
   "source": [
    "### Viewing Pieces of the Data\n",
    "\n",
    "When working with large `DataFrames` we may want to obtain a small sample of the `DataFrame` in order to get a quick overview of its organization (header, index, entries, etc....) without having to load it entirely. We had similar motivations in Chapter 2: *Loading and Storing data* when we introduced the `nrows` parameter of the `read_table()` and `read_csv()` `pandas` functions. \n",
    "\n",
    "Using the `head()` method we can make a new `DataFrame` with the same `columns` but with only the ***first*** $n$ rows rather than the entire `DataFrame` where * $n$ is an optional parameter that is by default 5. For example, if we want to make a new `DataFrame` made of only the first 2 rows of `spending_df`, then we would type:\n",
    "\n",
    "```python\n",
    ">>> spending_df.head(n=2)\n",
    "              doctor_id   specialty       medication  nb_beneficiaries  spending\n",
    "unique_id                                                                     \n",
    "NX531425   1255626040  FAMILY PRACTICE  METFORMIN HCL                30   135.24 \n",
    "QG879256   1699761833  FAMILY PRACTICE    ALLOPURINOL                30   715.76\n",
    "```\n",
    "\n",
    "We see that the `DataFrame` method `head()` with the optional parameter `n` set to 2 returns a new `DataFrame` with only 2 rows but the same number of columns as the `spending_df` `DataFrame`.\n",
    "\n",
    "Similarly, with the `tail()` method, we can make a new `DataFrame` with the same `columns` but with only the ***last*** $n$ rows rather than the entire `DataFrame` where * $n$, again, is an optional parameter that is by default 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0OYeUMpRYQT"
   },
   "outputs": [],
   "source": [
    "spending_df.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_B4yGYN_cv-"
   },
   "source": [
    "### DataFrame Axes\n",
    "\n",
    "We will begin to notice a concept of `axis` that is recurrent throughout the `pandas` `python` package. Many of the methods and functions we will see will have an optional `axis` parameter that may be set when the method of function is called. For instance, the methods `sum()`, `min()`, `max()`, etc.. can all be applied row- or column-wise. It helps to think about the operation as being carried across the axis.\n",
    "\n",
    "![](images/axis_example.png)\n",
    "\n",
    "The example seen in the image above is a visualization of how the `sum()` `DataFrame` method is carried out. The `sum()` method will calculate the sum of all the entries across either the rows or columns of the `DataFrame`, depending on how the optional `axis` parameter is set. Since the `axis` parameter of the `sum()` method is *optional*, it has a default setting, and in this case the default will be `axis=0` or equivalently `axis=rows`. However, this default may vary from method to method, so it is important to verify before use. \n",
    "\n",
    "When the `DataFrame` `sum()` method is called and the optional `axis` parameter is set to 0, or 'rows',  then the method will add up all the entries in the same column across all the rows, as is shown in the example above. \n",
    "\n",
    "We will see more examples of the `axis` parameter of `DataFrame` methods, and it will become more comfortable with practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RgUNUeEujno"
   },
   "source": [
    "### Descriptive Statistics\n",
    "\n",
    "`pandas` has many methods to compute the most common descriptive statistics such as the minimum, maximum, mean, variance, etc. The collection of `DataFrame` methods which will calculate the descriptive statistics can operate on either axis (column or row). \n",
    "\n",
    "Let us see some examples of computing descriptive statistics. We will start by creating a very simple `DataFrame`, call it `df`, which will help us illustrate what is happening.\n",
    "\n",
    "```python\n",
    ">>> df = pd.DataFrame({'A':[0,1,2], 'B':[5,6,7]})\n",
    ">>> df\n",
    "   A  B\n",
    "0  0  5\n",
    "1  1  6\n",
    "2  2  7\n",
    "```\n",
    "\n",
    "`df` is simply a $3 \\times 2$ `DataFrame` with numeric entries. If we wanted to calculate the mean of the all the row entries in each of the columns labeled `A` and `B`, then we could use the `mean()` `DataFrame` method with its default parameters, i.e. `axis='rows'`. \n",
    "\n",
    "``` python\n",
    ">>> df.mean()\n",
    "A    1.0\n",
    "B    6.0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "The resulting `Series` contains the mean of the columns `A` and `B`. Please note that the opeartion was carried across the \"rows\". \n",
    "\n",
    "Alternatively, if we wanted the mean of the column entries for each each row, then we would set the optional `axis` parameter of the `mean()` method to 1 or 'columns':\n",
    "\n",
    "```python\n",
    ">>> df.mean(axis=1)\n",
    "0    2.5\n",
    "1    3.5\n",
    "2    4.5\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "This time, we can see the mean of the rows. Also note that the operation is carried across the “columns”.\n",
    "\n",
    "Descriptive statistic methods can also be called by `Series` objects, i.e. individual rows and columns of the `DataFrame`. For example, if we only wanted to find the mean of all the entries in the column labeled by `A`, then we could first access the column `A` in `df` using the syntax: `df['A']`, and then call the `Series` `mean()` method on the returned `Series`. \n",
    "\n",
    "```python\n",
    ">>> df['A'].mean()\n",
    "1.0\n",
    "```\n",
    "\n",
    "We see that the mean of all the entries in the column `A` is $1.0$. Note that the `Series` `mean()` method does *not* have the optional `axis` parameter since it would not make sense to calculate the mean across the 'columns' of a `Series` since `Series` do not have multiple columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 445,
     "status": "ok",
     "timestamp": 1534190663139,
     "user": {
      "displayName": "Charles Dickens",
      "photoUrl": "//lh6.googleusercontent.com/-LyFY-SmW2Wk/AAAAAAAAAAI/AAAAAAAAAJc/aBlebAB4Y_M/s50-c-k-no/photo.jpg",
      "userId": "116926057727252856181"
     },
     "user_tz": 600
    },
    "id": "igP-4gtVXJSI",
    "outputId": "88a8193b-1cd2-41a2-bab8-6a3b9f96a0f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  0  5\n",
       "1  1  6\n",
       "2  2  7"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'A':[0,1,2], 'B':[5,6,7]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1534191029417,
     "user": {
      "displayName": "Charles Dickens",
      "photoUrl": "//lh6.googleusercontent.com/-LyFY-SmW2Wk/AAAAAAAAAAI/AAAAAAAAAJc/aBlebAB4Y_M/s50-c-k-no/photo.jpg",
      "userId": "116926057727252856181"
     },
     "user_tz": 600
    },
    "id": "f3dkBqdRX0nP",
    "outputId": "2f1bc994-f3a4-41f0-db29-258b0e3a9d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column wise mean:\n",
      "A    1.0\n",
      "B    6.0\n",
      "dtype: float64\n",
      "---------------\n",
      "Row wise mean:\n",
      "A    1.0\n",
      "B    6.0\n",
      "dtype: float64\n",
      "---------------\n",
      "Series mean:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print('Column wise mean:')\n",
    "print(df.mean())\n",
    "print('---------------')\n",
    "print('Row wise mean:')\n",
    "print(df.mean(axis=1))\n",
    "print('---------------')\n",
    "print('Series mean:')\n",
    "print(df['A'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2gCbrD7AVQyd"
   },
   "source": [
    "#### Descriptive Statistics on the Medical Spending Data Set\n",
    "\n",
    "Let us try and calculate some statistics for our Medical Spending Dataset, we will start with the mean\n",
    "\n",
    "```python\n",
    ">>> spending_df.mean()\n",
    "doctor_id           1.503766e+09\n",
    "nb_beneficiaries    5.091830e+01\n",
    "spending            4.333839e+03\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "Notice that the mean was calculated across the rows for all of the columns whose data type was numeric (int or float), and *not* for those whose data type was `object`. \n",
    "\n",
    "These results seem reasonable at first glance, but, if we look closely, it doesn't quite make sense to calculate the mean of the `doctor_id` column. We as humans can recognize that the `doctor_id` column is essentially just labels for each doctor that may have been assigned arbitrarily, so it would make more sense if the doctor IDs were instead stored as a `pandas` `object` type, since the `pandas` `object` type corresponds to the native `python` `string` data type. \n",
    "\n",
    "This is our first flaw that we shoud take note of in this dataset; we will learn how to clean this up in the following Chapter: *Data Cleaning*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UbhztYJapac"
   },
   "outputs": [],
   "source": [
    "spending_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cr-iw_-q08Qs"
   },
   "source": [
    "### Count\n",
    "\n",
    "Earlier we introduced and used the `shape` and `size` attributes of `DataFrames` and `Series`. Recall that the `shape` and `size` attributes tell us how many rows and columns there are and how many entries there are in a `DataFrame` or `Series` respectively, but these attributes include missing values in their counts. To illustrate the point lets build a `DataFrame` with all missing values and check its shape and size:\n",
    "\n",
    "```python\n",
    ">>> na_df = pd.DataFrame({1: [None, None], 2: [None, None]})\n",
    ">>> na_df.shape\n",
    "(2, 2)\n",
    ">>> na_df.size\n",
    "4\n",
    "```\n",
    "\n",
    "If we were none the wiser then we would say that there are 2 rows and 2 columns with a total of 4 values in the `DataFrame`, but there is actually no real data in this `DataFrame`, all the entries are blank. \n",
    "\n",
    "Intstead of using `shape` and `size` to understand how many data points we have, we can instead use the built in `count()` method for `DataFrames` and `Series`, which will exclude missing values. In other words, `count()` tells us the number of non-missing values in a `DataFrame` or `Series`.\n",
    "\n",
    "Let us take a look at a practical example. First let us read the data in the file 'spending_missing_values.csv'. This file is specifcally constructed to have some missing values to demonstrate this concept on an interesting life like data set.\n",
    "\n",
    "```python\n",
    ">>> spending_missing_values_df = pd.read_csv('spending_missing_values.csv', \n",
    "                                               index_col='unique_id', \n",
    "                                               na_values=['Null'])\n",
    "```\n",
    "\n",
    "Now let us call the `count()` method of the `spending_missing_values_df` `DataFrame` to see how many missing values there are in each column. The method has the optional `axis` parameter with a default of `axis=0`, or equivalently `axis=rows`.\n",
    "\n",
    "```python\n",
    ">>> spending_missing_values_df.count()\n",
    "doctor_id           54\n",
    "specialty           48\n",
    "medication          53\n",
    "nb_beneficiaries    50\n",
    "spending            50\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "The returned `Series` tells us the number of actual values in each `column` of the calling `DataFrame`. This `Series` shows us that there are many missing values in this `DataFrame`, and some columns have more missing values than others. \n",
    "\n",
    "If we wanted to know the total number of non-missing values in the `DataFrame` spending_missing_values_df, then we could call the `Series` `sum()` method on the returned `Series` from the `count()` call. For example, to find the total number of non-missing entries in the `DataFrame` `spending_missing_values_df` we would type:\n",
    "\n",
    "```python\n",
    ">>> spending_missing_values_df.count().sum()\n",
    "255\n",
    "```\n",
    "\n",
    "The `sum()` `Series` method added up all the values in the `Series` returned by the `counts()` call, i.e. $54 + 48 + 53 + 50 + 50 = 255$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJZmcKQXdYy1"
   },
   "outputs": [],
   "source": [
    "spending_missing_values_df = pd.read_csv('Data/spending_missing_values.csv', \n",
    "                                         index_col='unique_id', \n",
    "                                         na_values=['Null'])\n",
    "print(\"-------------Counts of Missing Values Across Rows----------------------\")\n",
    "print(spending_missing_values_df.count())\n",
    "print(\"---------------Total Count of Non-Missing Values-----------------------\")\n",
    "print(spending_missing_values_df.count().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nkBV89c8Zci3"
   },
   "source": [
    "### Value Counts \n",
    "\n",
    "Not only will we be interested in counting how many non-missing values there are in a `DataSet`, but we may also be interested in counting the number of occurences of a unique value. `value_counts()` is strictly a `Series` method and does exactly that; `value_counts()` tells us the frequency of each unique value in the `Series`. \n",
    "\n",
    "For example, suppose we wanted to count the frequency of occurence of each value in the `specialty` column of the `spending_df` `DataFrame`. To do this we would first access the `specialty` column of the `spending_df` `DataFrame`,  then we would call the `value_counts()` method with the retrieved `Series`:\n",
    "\n",
    "```python\n",
    ">>> spending_df['specialty'].value_counts()\n",
    "INTERNAL MEDICINE                                                 3060\n",
    "FAMILY PRACTICE                                                   2606\n",
    "NURSE PRACTITIONER                                                 822\n",
    ".\n",
    ".\n",
    ".\n",
    "Name: specialty, Length: 75, dtype: int64\n",
    "```\n",
    "\n",
    " The values in the resulting `Series` correspond to the frequency of occurence of each `specialty`, for instance we see that the value 'INTERNAL MEDICINE' shows up in the `spending_df` `DataFrame` `specialty` column $3060$ times. Also notice that the length of the `Series` can be interepreted as the number of unique values in the `spending_df` `DataFrame` `specialty` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOd7l47FdjEX"
   },
   "outputs": [],
   "source": [
    "spending_df['specialty'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "33IbJxKK2xhW"
   },
   "source": [
    "### The Describe Method\n",
    "\n",
    "If you just want a breif summary of your dataset including the main descriptive statistics and the counts then you can use the `describe()` method. By default, the `describe()` method will only describe the numeric columns, but we can set the `include` parameter to 'all' to see all of the columns described.\n",
    "\n",
    "First, let us look at the default description we are given when we call the `describe()` method for the `spending_df` `DataFrame`.\n",
    "\n",
    "```python\n",
    ">>> spending_df.describe()\n",
    "          doctor_id  nb_beneficiaries       spending\n",
    "count  1.000000e+04      10000.000000   10000.000000\n",
    "mean   1.503766e+09         50.918300    4333.838595\n",
    "std    2.874269e+08         86.493443   21915.925814\n",
    "min    1.003010e+09         11.000000      15.020000\n",
    "25%    1.255580e+09         15.000000     253.237500\n",
    "50%    1.508818e+09         24.000000     677.970000\n",
    "75%    1.750467e+09         50.000000    2442.955000\n",
    "max    1.992999e+09       1987.000000  892027.000000\n",
    "```\n",
    "\n",
    "We see that the returned object is a `DataFrame` with column labels equivalent to the numeric columns of the calling `DataFrame` (`spending_df` in this case) and index labels of different descriptive statistics. For instance, the entry in the row labeled 'count' at the column labeled 'spending' tells us the count of non-missing values there are in the column `spending`of the `spending_df` `DataFrame`, and the 25%, 50% and 75% rows are the percentile values. This information is all very useful when you are trying to understand your data set.\n",
    "\n",
    "Now let us see what happens when we set the optional `include`parameter of the `describe()` `DataFrame` method to 'all', i.e. `include='all'`.\n",
    "\n",
    "```python\n",
    ">>> spending_df.describe(include='all')\n",
    "           doctor_id          specialty            medication  nb_beneficiaries       spending\n",
    "count   1.000000e+04              10000                 10000      10000.000000   10000.000000\n",
    "unique           NaN                 75                   617               NaN            NaN\n",
    "top              NaN  INTERNAL MEDICINE  LEVOTHYROXINE SODIUM               NaN            NaN\n",
    "freq             NaN               3060                   150               NaN            NaN\n",
    "mean    1.503766e+09                NaN                   NaN         50.918300    4333.838595\n",
    "std     2.874269e+08                NaN                   NaN         86.493443   21915.925814\n",
    "min     1.003010e+09                NaN                   NaN         11.000000      15.020000\n",
    "25%     1.255580e+09                NaN                   NaN         15.000000     253.237500\n",
    "50%     1.508818e+09                NaN                   NaN         24.000000     677.970000\n",
    "75%     1.750467e+09                NaN                   NaN         50.000000    2442.955000\n",
    "max     1.992999e+09                NaN                   NaN       1987.000000  892027.000000\n",
    "```\n",
    "\n",
    "We now see that the returned `DataFrame` from the `describe()` call includes all of the columns of the `spending_df` `DataFrame`. Also notice that there are additional rows labeled 'top' and 'freq'. The 'top' and 'freq' row entries tell us the most common entry in the column and the corresponding frequency of that top entry respectively. \n",
    "\n",
    "The 'top' and 'freq' row entries are NaN, i.e. missing, for the numeric columns. This is because it doesn't quite make sense to calculate those statistics for the numeric columns. Similarly the count, mean, std, etc. row entries are NaN in the object type columns, since we cannot calculate these statistics in the object columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47v6pq8-eu-m"
   },
   "outputs": [],
   "source": [
    "spending_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAoAoPNXexkT"
   },
   "outputs": [],
   "source": [
    "spending_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "spCbYjeY6Afg"
   },
   "source": [
    "## Exercise 3.2: `DataFrame` Methods\n",
    "\n",
    "Which of the following lines of code will output the average arrival delay time for the flights described in `HNL_flights_df`? Note that the output should be: -2.2572254335260116\n",
    "\n",
    "A:\n",
    "```python\n",
    "HNL_flights_df['ARRIVAL_DELAY'].mean()\n",
    "```\n",
    "\n",
    "B:\n",
    "```python\n",
    "HNL_flights_df.mean()\n",
    "```\n",
    "\n",
    "C:\n",
    "```python\n",
    "pd.mean(HNL_flights_df.ARRIVAL_DELAY)\n",
    "```\n",
    "\n",
    "D:\n",
    "```python\n",
    "HNL_flights_df.describe().ARRIVAL_DELAY\n",
    "```\n",
    "\n",
    "Hint: Feel free to use the code cell below to try these commands out. For the incorrect options, make note of what is going wrong and or what errors are being thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQlBznsp9l49"
   },
   "outputs": [],
   "source": [
    "# Exercise 3.2 Scratch Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qcm-BNiPgSsM"
   },
   "source": [
    "# Arithmetic and Data Alignment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ft4T8eRUiJW9"
   },
   "source": [
    "## Vectorization\n",
    "\n",
    "***Vectorization*** is simply operations applied index by index to array like data structures. Vectorization is important since it is a much more efficient alternative to for loops in `Python`. \n",
    "\n",
    "`pandas` seamlessly supports vectorization. A key feature of pandas `Series` and `DataFrames` is that when executing an arithmetic operation, the `Series` or `DataFrames` will first be aligned by their matching indices and applied in a pairwise fashion. A new index is created from the union of the indices of both `Series` or `DataFrames` and values for indices present in only one of the `Series` or `DataFrames` are filled with missing values (NaN). \n",
    "\n",
    "In the following cells we will be seeing examples of how to perform vectorized operations on `Series` and `DataFrames`. To demonstrate the process without getting lost in the complexities of a life like dataset we will be working with two very basic `DataFrames`, call them `df_1` and `df_2`, that we will construct like so:\n",
    "\n",
    "```python\n",
    "df_1 = pd.DataFrame({'AA':{'A':79, 'C':2, 'T':12, 'X':21},\n",
    "                     'BB':{'A':11, 'C':2, 'T':2, 'X':9}})\n",
    "df_2 = pd.DataFrame({'AA':{'A':21,'D':14,'T':5},\n",
    "                     'CC':{'A':12,'D':28,'T':121}})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nPMiIVzJy7cc"
   },
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame({'AA':{'A':79, 'C':2, 'T':12, 'X':21},\n",
    "                     'BB':{'A':11, 'C':2, 'T':2, 'X':9}})\n",
    "df_2 = pd.DataFrame({'AA':{'A':21,'D':14,'T':5},\n",
    "                     'CC':{'A':12,'D':28,'T':121}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YfChLH62O48W"
   },
   "source": [
    "### Vectorized Arithmetic Between `Series` (`DataFrame` columns)\n",
    "\n",
    "Let us first look at an example of performing arithmetic between `pandas` `Series`. If we wanted to add the column labeled 'AA' in `df_1` to the column labeled \"AA\" in `df_2` we would type:\n",
    "\n",
    "```python\n",
    "df_1[\"AA\"] + df_2[\"AA\"]\n",
    "```\n",
    "\n",
    "![](images/alignment_arithmetic_col.png)\n",
    "\n",
    "The image above breaks down the process of adding the `Series`. First we see that the two columns, both labeled 'AA' are accessed from the `DataFrame` `df_1` and `df_2` by typing `df_1['AA']` and `df_2['AA']` respectively. Second, the two column `Series` are aligned by the their individual indices. Notice in the image that the `Series` `df_1['AA']` was extended to include the new entry labled 'D' and the new row entry was populated by `NaN`. Similarly the `Series` `df_2['AA']` was extended to include two new entries with labels 'C' and 'X' and they too were populated with `NaNs`. Lastly, the two extended `Series` are added together to make a new `Series` with an index equivalent to the union of the indices of both of the two `Series` `df_1['AA']` and `df_2['AA']`. Each entry of the new `Series` is the sum of the entries with the same labels in `df_1['AA']` and `df_2['AA']`, but notice that if either one of the entries in the `Series` was `NaN`, then the result was also `NaN`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAmUUSvF2xRh"
   },
   "outputs": [],
   "source": [
    "df_1[\"AA\"] + df_2[\"AA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ErZIn1TSP5KI"
   },
   "source": [
    "### Vectorized Arithmetic Between `Series` (`DataFrame` Row)\n",
    "\n",
    "The process behind adding row `Series` is very similar to the process of adding column `Series`, the only difference is that we initially acess the rows of the two `DataFrames`. For instance, to add the row `Series` `df_1.loc[\"A\", :]` to the row `Series`  `df_2.loc[\"D\", :]` we would type:\n",
    "\n",
    "```python\n",
    "df_1.loc[\"A\"] + df_2.loc[\"D\"]\n",
    "```\n",
    "\n",
    "![](images/alignment_arithmetic_row.png)\n",
    "\n",
    "\n",
    "The image above again breaks down the process of what is happening when we run this small command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41SxTmdV5wvU"
   },
   "outputs": [],
   "source": [
    "df_1.loc[\"A\"] + df_2.loc[\"D\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIG2G5gkPADE"
   },
   "source": [
    "### Vectorized Arithmetic Between DataFrames\n",
    "\n",
    "Our final example is arithmetic between two entire `DataFrames`. The concept behind what is happening here is just an extension of both adding row and column `Series`; when we add two `DataFrames` in a vectorized way, the alignment is with both the row and column index. For example let us add the two `DataFrames` `df_1` and df_2`.\n",
    "\n",
    "```python\n",
    "df_1 + df_2\n",
    "```\n",
    "\n",
    "![](images/alignment_arithmetic_df.png)\n",
    "\n",
    "The image above breaks down the two step process of adding the `DataFrames`. First the `DataFrames` are extended so that they have matching column labels and indices. Then the `DataFrames` are added entry by entry, meaning the entries with the same index and column label are added, to create a new `DataFrame`. Remember that if an entry that is missing is added to a another entry, then the missing value, `NaN`, will carry through to the new `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1534192063202,
     "user": {
      "displayName": "Charles Dickens",
      "photoUrl": "//lh6.googleusercontent.com/-LyFY-SmW2Wk/AAAAAAAAAAI/AAAAAAAAAJc/aBlebAB4Y_M/s50-c-k-no/photo.jpg",
      "userId": "116926057727252856181"
     },
     "user_tz": 600
    },
    "id": "oUlho1G3ne1P",
    "outputId": "643ae759-cf1d-4491-9e28-b60bd60f3cad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA</th>\n",
       "      <th>BB</th>\n",
       "      <th>CC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AA  BB  CC\n",
       "A  100.0 NaN NaN\n",
       "C    NaN NaN NaN\n",
       "D    NaN NaN NaN\n",
       "T   17.0 NaN NaN\n",
       "X    NaN NaN NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 + df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKrdPyVogezm"
   },
   "source": [
    "## Vectorization Example with the Medical Spending Data Set\n",
    "\n",
    "We have seen vectorization with basic `DataFrames`, now at a more concrete example . What if we wanted to calculate the average spending per beneficiary of the `spending_df` `DataFrame`?\n",
    "\n",
    "To do this we could first make a new `Series` that is the spending per benificiary by dividing `spending` column by the 'nb_beneficiaries' column. Then the average of this new `Series` can be calculated by calling the `mean()` method.  This can all be done in one line by chaining the operations together.\n",
    "\n",
    "```python\n",
    ">>>> (spending_df['spending'] / spending_df['nb_beneficiaries']).mean()\n",
    "131.92616419345254\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9yZ2OYGftw6"
   },
   "outputs": [],
   "source": [
    "(spending_df['spending'] / spending_df['nb_beneficiaries']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVxb8RGe3N-a"
   },
   "source": [
    "## Exercise 3.3: Vectorization\n",
    "\n",
    "Which of the following lines of code will result in a `Series` that contains the average speed of the plane in miles per minute for each flight decribed in  HNL_flights_df? Please note that this can be calculated by dividing the distance by the air time of the flight.\n",
    "\n",
    "A:\n",
    "```python\n",
    "HNL_flights_df.loc[:, 'DISTANCE' / 'AIR_TIME']\n",
    "```\n",
    "\n",
    "B:\n",
    "```python\n",
    "HNL_flights_df.loc['DISTANCE', :] / HNL_flights_df.loc['AIR_TIME', :]\n",
    "```\n",
    "\n",
    "C:\n",
    "```python\n",
    "HNL_flights_df.loc[:, 'DISTANCE'] / HNL_flights_df.loc[:, 'AIR_TIME']\n",
    "```\n",
    "\n",
    "D:\n",
    "```python\n",
    "HNL_flights_df.loc[:, ['DISTANCE', 'AIR_TIME']].divide(HNL_flights_df.loc[:, 'AIR_TIME'], axis='rows')\n",
    "```\n",
    "\n",
    "Hint: Feel free to use the code cell below to try these commands out. For the incorrect options, make note of what is going wrong and or what errors are being thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3CEGz95h8VEs"
   },
   "outputs": [],
   "source": [
    "# Exercise 3.3 Scratch Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5pyeKdsiMyT"
   },
   "source": [
    "## Broadcasting\n",
    "\n",
    "Arithmetic operations between `Series` or `DataFrames` and a scalar require expanding the scalar into a `Series` or `DataFrame` of the same dimension. This process of expanding a single value into a `Series` or `DataFrame` is called **broadcasting**. \n",
    "\n",
    "For example, suppose we wanted to add the value 1.2 to `Series` `df_1['AA']`, where `df_1` is the same `DataFrame` we were using in the section on *Vectorization*.  To do this, all we would need to type is the following:\n",
    "\n",
    "```python\n",
    "df_1['AA'] + 1.2\n",
    "```\n",
    "\n",
    "![](images/alignment.png)\n",
    "\n",
    "\n",
    "The image above shows what is happening when we type this command. We see that a new `Series` is created with an index matching the index of `df_1['AA']` and with entries of all the same value, 1.2. This new `Series` is aligned with `df_1['AA']` and added entry by entry, just like in the *Vectorization* examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYL_NlZmnmFu"
   },
   "outputs": [],
   "source": [
    "df_1['AA'] + 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSOZ-BzsDShV"
   },
   "source": [
    "## Exercise 3.4: Broadcasting\n",
    "\n",
    "Currently the `AIR_TIME` column, which gives the total flight time without taxiing, is in units of minutes. Which of the following lines of code will result in a `Series` that contains the total flight time without taxiing in units of hours? Please note that this can be found by dividing each of the entries in the `AIR_TIME` column by sixty.\n",
    "\n",
    "A:\n",
    "```python\n",
    "HNL_flights_df.loc[:, 'AIR_TIME'] / pd.DataFrame([60])\n",
    "```\n",
    "\n",
    "B:\n",
    "```python\n",
    "HNL_flights_df.loc[:, 'AIR_TIME'] / pd.Series([60])\n",
    "```\n",
    "\n",
    "C:\n",
    "```python\n",
    "HNL_flights_df.loc['AIR_TIME', :] / 60\n",
    "```\n",
    "\n",
    "D:\n",
    "```python\n",
    "HNL_flights_df.loc[:, 'AIR_TIME'] / 60\n",
    "```\n",
    "\n",
    "Hint: Feel free to use the code cell below to try these commands out. For the incorrect options, make note of what is going wrong and or what errors are being thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RF8mhDhAGyyH"
   },
   "outputs": [],
   "source": [
    "# Exercise 3.4 Scratch Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rDqp54zSkBIM"
   },
   "source": [
    "# Summary\n",
    "\n",
    "---\n",
    "\n",
    "**Summarizing Your Data**\n",
    "\n",
    "* Important Attributes:\n",
    "\n",
    "| Attribute |Description|\n",
    "|:----------|-----------|\n",
    "| `shape`| Return a tuple representing the dimensionality of the DataFrame. |\n",
    "| `size` | Return an int representing the number of elements in this object.  |\n",
    "| `dtypes` | Return the dtypes in the DataFrame. |\n",
    "\n",
    "* Important Methods:\n",
    "\n",
    "| Method|Description|\n",
    "|:----------|-----------|\n",
    "| `head()`| Return the first n rows. |\n",
    "| `tail()` | Return the last n rows. |\n",
    "| `min()`, `max()` | Computes the numeric (for numeric value) or alphanumeric (for object values) row-wise min, max in a Series or DataFrame|\n",
    "| `sum()`, `mean()`, `std()`, `var()`   |  Computes the row-wise sum, mean, standard deviation and variance in a `Series` or DataFrame|\n",
    "|`nlargest()`|\tReturn the first n rows ordered by the spceified columns in descending order. |\n",
    "| `count()` |  returns the number of non-NaN values in the in a `Series` or `DataFrame` |\n",
    "| `value_counts()` |  returns the frequency for each value in the `Series` |\n",
    "| `describe()` | Computes row-wise statistics |\n",
    "\n",
    "\n",
    "**Arithmetic and Data Alignment**\n",
    "\n",
    "* When executing an arithmetic operation between `Series` or `DataFrames`, the object will first be extended and then aligned by their indices and then the arithmetic will be applied in a pairwise fashion, this is called *vectorized arithmetic between `Series` or `DataFrames`*\n",
    "\n",
    "![](images/alignment_arithmetic_col.png)\n",
    "\n",
    "* When executing an arithmetic operation between constants and `Series` or `Dataframes`, the constant will be extended to a new `Series` or `DataFrame` to align with the first `Series` or `Dataframe` and then the arithmetic will be applied in a pairwise fashion, this is referred to as *broadcasting*\n",
    "\n",
    "![](images/alignment.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0LJYevev1Ppg"
   ],
   "name": "3_Exploring_Data.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
